{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1rg5xta8T40fZmr7aZaW4dJDn7zb1UH_l",
      "authorship_tag": "ABX9TyP3saHlh33leZnXAMLoWBsg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaiDuc1001/Flower-Diffusion-Model/blob/main/Flower_(64x64)_Generator_with_Diffusion_UNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WandB and dependencies"
      ],
      "metadata": {
        "id": "6WoUP0Mq2WdK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvRXo7qYod6q"
      },
      "outputs": [],
      "source": [
        "!pip install wandb --quiet\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras import utils, callbacks, metrics, losses, activations\n",
        "\n",
        "import wandb\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "metadata": {
        "id": "i89EB8aGqGdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract"
      ],
      "metadata": {
        "id": "rQuMcioy2Z0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ZIP_PATH = \"/content/drive/MyDrive/Datasets/102flowers/102flowers.tgz\"\n",
        "if not os.path.exists(\"/content/data\"):\n",
        "    os.mkdir(\"/content/data\")\n",
        "\n",
        "with tarfile.open(ZIP_PATH, \"r\") as tar:\n",
        "    tar.extractall(\"/content/data\")"
      ],
      "metadata": {
        "id": "5k7qmcXrqn_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR = \"/content/data/jpg\"\n",
        "images_names = os.listdir(ROOT_DIR)"
      ],
      "metadata": {
        "id": "oAdRJipmrqcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config hyperparameters"
      ],
      "metadata": {
        "id": "PX5Xgsy42bmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"ARCHITECTURE\": \"UNET\",\n",
        "    \"IMAGE_SIZE\": 64,\n",
        "    \"BATCH_SIZE\": 64,\n",
        "    \"REPETITION\": 5,\n",
        "    \"NOISE_EMBEDDING_SIZE\": 32,\n",
        "    \"LEARNING_RATE\": 1e-3,\n",
        "    \"WEIGHT_DECAY\": 1e-4,\n",
        "    \"EMA\": 0.99,\n",
        "    \"PLOT_DIFFUSION_STEP\": 20,\n",
        "    \"EPOCHS\": 50\n",
        "}\n",
        "wandb.init(project=\"Flower_Generator_with_Diffusion_UNET\", config=config)\n",
        "config = wandb.config"
      ],
      "metadata": {
        "id": "EHpME7VNtov7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize dataset"
      ],
      "metadata": {
        "id": "0hE1jtXF2e0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = utils.image_dataset_from_directory(\n",
        "    ROOT_DIR,\n",
        "    labels=None,\n",
        "    image_size=(config.IMAGE_SIZE, config.IMAGE_SIZE),\n",
        "    batch_size=None,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    interpolation=\"bilinear\"\n",
        ")"
      ],
      "metadata": {
        "id": "AQyCa9vgsbia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "    image = tf.cast(image, \"float32\") / 255.0\n",
        "    return image\n",
        "\n",
        "train = train_dataset.map(lambda x: preprocess_image(x))\n",
        "train = train.repeat(config.REPETITION)\n",
        "train = train.batch(config.BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "9MxXi-ZqwKEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = train.take(1).get_single_element().numpy()\n",
        "plt.imshow(batch[0])\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "IDPXKJ3Ewj_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diffusion"
      ],
      "metadata": {
        "id": "Z8zQdsAL2iLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diffusion schedules"
      ],
      "metadata": {
        "id": "vSksBG4b2jqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_diffusion_schedule(diffusion_times):\n",
        "    min_rate = 1e-4\n",
        "    max_rate = 2e-2\n",
        "    betas = min_rate + diffusion_times * (max_rate - min_rate)\n",
        "    alphas = 1 - betas\n",
        "    alpha_bars = tf.math.cumprod(alphas)\n",
        "    signal_rates = tf.sqrt(alpha_bars)\n",
        "    noise_rates = tf.sqrt(1-alpha_bars)\n",
        "    return signal_rates, noise_rates\n",
        "\n",
        "def cosine_diffusion_schedule(diffusion_times):\n",
        "    signal_rates = tf.cos(diffusion_times * math.pi / 2)\n",
        "    noise_rates = tf.sin(diffusion_times * math.pi / 2)\n",
        "    return signal_rates, noise_rates\n",
        "\n",
        "def offset_cosine_diffusion_schedule(diffusion_times):\n",
        "    min_signal_rate = 2e-2\n",
        "    max_signal_rate = 0.95\n",
        "    start_angle = tf.acos(max_signal_rate)\n",
        "    end_angle = tf.acos(min_signal_rate)\n",
        "    diffusion_angle = start_angle + diffusion_times * (end_angle - start_angle)\n",
        "    signal_rates = tf.cos(diffusion_angle)\n",
        "    noise_rates = tf.sin(diffusion_angle)\n",
        "    return signal_rates, noise_rates"
      ],
      "metadata": {
        "id": "ZbwwTI7DxYak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 1000\n",
        "diffusion_times = tf.convert_to_tensor([x/T for x in range(T)])\n",
        "linear_signal_rates, linear_noise_rates = linear_diffusion_schedule(diffusion_times)\n",
        "cosine_signal_rates, cosine_noise_rates = cosine_diffusion_schedule(diffusion_times)\n",
        "offset_cosine_signal_rates, offset_cosine_noise_rates = offset_cosine_diffusion_schedule(diffusion_times)"
      ],
      "metadata": {
        "id": "RCMW6jhQzVnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(diffusion_times, linear_signal_rates**2, linewidth=1.5, label=\"linear\")\n",
        "plt.plot(diffusion_times, cosine_signal_rates**2, linewidth=1.5, label=\"cosine\")\n",
        "plt.plot(diffusion_times, offset_cosine_signal_rates**2, linewidth=1.5, label=\"offset_cosine\")\n",
        "\n",
        "plt.xlabel(\"t/T\", fontsize=12)\n",
        "plt.ylabel(r\"$\\bar{\\alpha_t}$ (signal)\", fontsize=12)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cph_dhkozu2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Cosine is outperforming the linear one. \\\n",
        "Note: Why offset looks like \"smoother\" than cosine is because max_rate is 0.95 not 1. If it is set to 1. then the 2 curves will look the same."
      ],
      "metadata": {
        "id": "WP5Eac9608HS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sinusoidal embedding (positional encoding in Transformer)"
      ],
      "metadata": {
        "id": "KDKVtij-2mA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sinusoidal_embedding(x):\n",
        "    frequencies = tf.exp(tf.linspace(\n",
        "        tf.math.log(1.0),\n",
        "        tf.math.log(1000.0),\n",
        "        config.NOISE_EMBEDDING_SIZE // 2 # 32 // 2 = 16\n",
        "    ))\n",
        "    angular_speed = 2.0 * math.pi * frequencies\n",
        "    embeddings = tf.concat(\n",
        "        [tf.sin(angular_speed * x), tf.cos(angular_speed * x)], axis=3\n",
        "    )\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "whBbG6d80YdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_list = []\n",
        "for y in np.arange(0, 1, 0.01):\n",
        "    embedding_list.append(sinusoidal_embedding(np.array([[[[y]]]]))[0][0][0])\n",
        "embedding_array = np.array(np.transpose(embedding_list))\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.set_xticks(np.arange(0, 100, 10), labels=np.round(np.arange(0, 1, 0.1), 1))\n",
        "ax.set_xlabel(\"Noise variance\", fontsize=8)\n",
        "ax.set_ylabel(\"Embedding dimension\", fontsize=8)\n",
        "plt.pcolor(embedding_array, cmap=\"coolwarm\")\n",
        "plt.colorbar(orientation=\"horizontal\", label=\"embedding values\")\n",
        "ax.imshow(embedding_array, interpolation=\"nearest\", origin=\"lower\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wkafVPOy4J5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Architecture"
      ],
      "metadata": {
        "id": "rIwTNVCg8lKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "def ResidualBlock(width):\n",
        "    def apply(x):\n",
        "        input_width = x.shape[3] # channels\n",
        "        if input_width == width:\n",
        "            residual = x\n",
        "        else:\n",
        "            residual = layers.Conv2D(width, kernel_size=1)(x)\n",
        "        x = layers.BatchNormalization(center=False, scale=False)(x)\n",
        "        x = layers.Conv2D(\n",
        "            width, kernel_size=3, padding=\"same\", activation=activations.swish\n",
        "        )(x)\n",
        "        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n",
        "        x = layers.Add()([x, residual])\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def DownBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        for _ in range(block_depth):\n",
        "            x = ResidualBlock(width)(x)\n",
        "            skips.append(x)\n",
        "        x = layers.AveragePooling2D(pool_size=2)(x)\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "\n",
        "def UpBlock(width, block_depth):\n",
        "    def apply(x):\n",
        "        x, skips = x\n",
        "        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n",
        "        for _ in range(block_depth):\n",
        "            x = layers.Concatenate()([x, skips.pop()])\n",
        "            x = ResidualBlock(width)(x)\n",
        "        return x\n",
        "\n",
        "    return apply\n",
        "\n",
        "noisy_images = layers.Input(shape=(config.IMAGE_SIZE, config.IMAGE_SIZE, 3))\n",
        "x = layers.Conv2D(32, kernel_size=1)(noisy_images)\n",
        "\n",
        "noise_variances = layers.Input(shape=(1, 1, 1))\n",
        "noise_embedding = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
        "noise_embedding = layers.UpSampling2D(size=config.IMAGE_SIZE, interpolation=\"nearest\")(\n",
        "    noise_embedding\n",
        ")\n",
        "\n",
        "x = layers.Concatenate()([x, noise_embedding])\n",
        "\n",
        "skips = []\n",
        "\n",
        "x = DownBlock(32, block_depth=2)([x, skips])\n",
        "x = DownBlock(64, block_depth=2)([x, skips])\n",
        "x = DownBlock(96, block_depth=2)([x, skips])\n",
        "\n",
        "x = ResidualBlock(128)(x)\n",
        "x = ResidualBlock(128)(x)\n",
        "\n",
        "x = UpBlock(96, block_depth=2)([x, skips])\n",
        "x = UpBlock(64, block_depth=2)([x, skips])\n",
        "x = UpBlock(32, block_depth=2)([x, skips])\n",
        "\n",
        "x = layers.Conv2D(3, kernel_size=1, kernel_initializer=\"zeros\")(x)\n",
        "\n",
        "unet = models.Model([noisy_images, noise_variances], x, name=\"unet\")"
      ],
      "metadata": {
        "id": "VTvLnyPm8mwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diffusion Class"
      ],
      "metadata": {
        "id": "BMMS72g0_wpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionModel(models.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.normalizer = layers.Normalization()\n",
        "        self.network = unet\n",
        "        self.ema_network = models.clone_model(self.network)\n",
        "        self.diffusion_schedule = offset_cosine_diffusion_schedule\n",
        "\n",
        "    def compile(self, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.noise_loss_tracker = metrics.Mean(name=\"n_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.noise_loss_tracker]\n",
        "\n",
        "    def denormalize(self, images):\n",
        "        images = self.normalizer.mean + self.normalizer.variance**0.5 * images\n",
        "        images = tf.clip_by_value(images, 0.0, 1.0)\n",
        "        return images\n",
        "\n",
        "    def denoise(self, noisy_images, signal_rates, noise_rates, training):\n",
        "        if training:\n",
        "            network = self.network\n",
        "        else:\n",
        "            network = self.ema_network\n",
        "\n",
        "        pred_noises = network([noisy_images, noise_rates**2], training=training)\n",
        "        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
        "        return pred_noises, pred_images\n",
        "\n",
        "    def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
        "        num_images = initial_noise.shape[0]\n",
        "        step_size = 1.0 / diffusion_steps\n",
        "        current_images = initial_noise\n",
        "        for step in range(diffusion_steps):\n",
        "            diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size\n",
        "            signal_rates, noise_rates = self.diffusion_schedule(diffusion_times)\n",
        "            pred_noises, pred_images = self.denoise(\n",
        "                current_images, signal_rates, noise_rates, training=False\n",
        "            )\n",
        "            next_diffusion_times = diffusion_times - step_size\n",
        "            # Calculate sqrt(\\bar{\\alpha}_{t-1})\n",
        "            next_signal_rates, next_noise_rates = self.diffusion_schedule(next_diffusion_times)\n",
        "            current_images = (next_signal_rates * pred_images + next_noise_rates * pred_noises)\n",
        "        return pred_images\n",
        "\n",
        "    def generate(self, num_images, diffusion_steps, initial_noise=None):\n",
        "        if initial_noise is None:\n",
        "            initial_noise = tf.random.normal(\n",
        "                shape=(num_images, config.IMAGE_SIZE, config.IMAGE_SIZE, 3)\n",
        "            )\n",
        "        generated_images = self.reverse_diffusion(initial_noise, diffusion_steps)\n",
        "        generated_images = self.denormalize(generated_images)\n",
        "        return generated_images\n",
        "\n",
        "    def train_step(self, images):\n",
        "        images = self.normalizer(images, training=True)\n",
        "        noises = tf.random.normal((config.BATCH_SIZE, config.IMAGE_SIZE, config.IMAGE_SIZE, 3))\n",
        "        diffusion_times = tf.random.uniform(\n",
        "            shape=(config.BATCH_SIZE, 1, 1, 1), minval=0.0, maxval=1.0\n",
        "        )\n",
        "        signal_rates, noise_rates = self.diffusion_schedule(diffusion_times)\n",
        "        noisy_images = (signal_rates * images + noise_rates * noises)\n",
        "        with tf.GradientTape() as tape:\n",
        "            pred_noises, pred_images = self.denoise(\n",
        "                noisy_images, signal_rates, noise_rates, training=True\n",
        "            )\n",
        "            noise_loss = self.loss(noises, pred_noises)\n",
        "        gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n",
        "        self.noise_loss_tracker.update_state(noise_loss)\n",
        "\n",
        "        # Update EMA model\n",
        "        for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n",
        "            ema_weight.assign(config.EMA * ema_weight + (1-config.EMA) * weight)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "EKNDzwno00Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ImageGenerator Callback"
      ],
      "metadata": {
        "id": "BpG9td5Ahs53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display(images, n=8, title=\"Generated Images\"):\n",
        "    images = images[:n]\n",
        "    grid = [wandb.Image(img) for img in images]\n",
        "    wandb.log({title: grid})\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "    def __init__(self, num_images):\n",
        "        self.num_images = num_images\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        generated_images = self.model.generate(\n",
        "            num_images=self.num_images,\n",
        "            diffusion_steps=config.PLOT_DIFFUSION_STEP\n",
        "        ).numpy()\n",
        "        display(generated_images)\n",
        "\n",
        "class NoiseLossCallback(callbacks.Callback):\n",
        "    def __init__(self, wandb):\n",
        "        super().__init__()\n",
        "        self.wandb = wandb\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is not None:\n",
        "            self.wandb.log(logs)\n",
        "\n",
        "image_generator = ImageGenerator(num_images=8)\n",
        "noise_loss_callback = NoiseLossCallback(wandb)"
      ],
      "metadata": {
        "id": "_UjBrdP1HlAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main training"
      ],
      "metadata": {
        "id": "1jEY3WKShv0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddm = DiffusionModel()\n",
        "ddm.normalizer.adapt(train)"
      ],
      "metadata": {
        "id": "UGgSPVWykCZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.init(project=\"Flower_Generator_with_Diffusion_UNET\", config=config)\n",
        "K.clear_session()\n",
        "ddm.compile(\n",
        "    optimizer=optimizers.AdamW(learning_rate=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY),\n",
        "    loss = losses.mean_absolute_error\n",
        ")\n",
        "for var in ddm.optimizer.variables():\n",
        "    var.assign(tf.zeros_like(var))\n",
        "ddm.fit(\n",
        "    train,\n",
        "    epochs=config.EPOCHS,\n",
        "    use_multiprocessing = True,\n",
        "    callbacks=[image_generator, noise_loss_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "yO-QBi0Dhw6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "YyVzFVDNuQqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for diffusion_steps in list(range(1, 6, 1)) + [20] + [100]:\n",
        "    tf.random.set_seed(42)\n",
        "    generated_images = ddm.generate(\n",
        "        num_images=8,\n",
        "        diffusion_steps=diffusion_steps\n",
        "    ).numpy()\n",
        "    display(generated_images, title=\"Changes through diffusion steps\")"
      ],
      "metadata": {
        "id": "Zcy2xcgKuOem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddm.save(\"/content/ddm_64x64_50e\", save_format=\"h5\")"
      ],
      "metadata": {
        "id": "p3V7CIgPGVDL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}